{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_modelado_entrenarModelo_def_m2_ind.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/mjevans26/Satellite_ComputerVision/blob/master/UNET_G4G_2019_solar.ipynb","timestamp":1601503809515}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_MJ4kW1pEhwP"},"source":["# Librerias"]},{"cell_type":"code","metadata":{"id":"2slBbBa5kdYi"},"source":["!pip install tensorflow==2.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbMnlHWXktqx"},"source":["!pip install tensorflow-probability==0.10.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7iJd7w8j-cY"},"source":["! pip install -U segmentation-models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JKDKpX4FtQA1"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwvzCpUInKGi"},"source":["# Import, authenticate and initialize the Earth Engine library.\n","import ee\n","ee.Authenticate()\n","ee.Initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJNW2K4gx5Od"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1nRWFeJx8bT"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RnZzcYhcpsQ"},"source":["# Tensorflow setup.\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","device_name = tf.test.gpu_device_name()\n","tf.executing_eagerly()\n","print(tf.__version__)\n","print(device_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"at6948Jtn4DV"},"source":["%env SM_FRAMEWORK=tf.keras\n","import segmentation_models as sm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0bGy9tc2IiY2"},"source":["import matplotlib.pyplot as plt \n","import numpy as np\n","import glob\n","import os\n","from os.path import join"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iT8ycmzClYwf"},"source":["# Configuraciones"]},{"cell_type":"code","metadata":{"id":"psz7wJKalaoj"},"source":["# NOMBRE DEL PROYECTO\n","PROYECTO = 'Def2_ind_Planet'\n","BUCKET = 'mineriapr'\n","\n","# BANDAS Y VARIABLE RESPUESTA\n","opticalBands = ['R', 'G', 'B', 'NIR', 'NDVI', 'R2', 'G2', 'B2', 'NIR2', 'NDVI2']\n","#opticalBands = ['R', 'G', 'B']\n","BANDS = opticalBands\n","RESPONSE = 'landcover'\n","FEATURES = BANDS + [RESPONSE]\n","\n","# ESPECIFICACIONES DE LOS DATOS DE ENTRADA DEL MODELO DE SEGMENTACIÓN\n","KERNEL_SIZE = 256\n","KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n","COLUMNS = [\n","  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n","]\n","FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n","\n","# ESPECIFICACIONES DE LOS DATOS DE ENTRENAMIENTO DEL MODELO\n","BATCH_SIZE = 16\n","BUFFER_SIZE = 200"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5h6sGKxNpoDb"},"source":["BUCKET = 'mineriapr'\n","!gcloud auth login\n","!gcloud auth application-default login\n","#!gcloud auth application-default login\n","project_id = 'landai-270016'\n","!gcloud config set project {project_id}\n","!gsutil ls\n","!gsutil ls 'gs://mineriapr/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cC-zatoXNdlO"},"source":["## Funciones preparación de los datos"]},{"cell_type":"code","metadata":{"id":"ajyp48-vINuy"},"source":["def aug_color(img):\n","    n_ch = tf.shape(img)[-1]\n","    contra_adj = 0.05\n","    bright_adj = 0.05\n","\n","    ch_mean = tf.math.reduce_mean(img, axis = (0,1), keepdims = True)\n","    #ch_mean = np.mean(img, axis=(0, 1), keepdims=True).astype(np.float32)\n","\n","    contra_mul = tf.random.uniform(shape = (1, 1, n_ch),\n","                                   minval = 1-contra_adj,\n","                                   maxval = 1+contra_adj)\n","    # contra_mul = np.random.uniform(1 - contra_adj, 1 + contra_adj, (1, 1, n_ch)).astype(\n","    #     np.float32\n","    # )\n","\n","    bright_mul = tf.random.uniform(shape = (1, 1, n_ch),\n","                                   minval = 1 - bright_adj,\n","                                   maxval = 1+bright_adj)\n","    # bright_mul = np.random.uniform(1 - bright_adj, 1 + bright_adj, (1, 1, n_ch)).astype(\n","    #     np.float32\n","    # )\n","\n","    recolored = (img - ch_mean) * contra_mul + ch_mean * bright_mul\n","    return recolored\n","  \n","def normalize(x, axes=[0, 1, 2], epsilon=1e-8):\n","  \"\"\"\n","  Standardize incoming image patches by local mean and variance\n","  Parameters:\n","    x (tensor): nD image tensor\n","    axes (array): Array of ints. Axes along which to compute mean and variance, usually length n-1\n","    epsilon (float): small number to avoid dividing by zero\n","  Return:\n","    tensor: nD image tensor normalized by channels\n","  \"\"\"\n","  mean, variance = tf.nn.moments(x, axes=axes)\n","  x_normed = (x - mean) / tf.sqrt(variance + epsilon) # epsilon to avoid dividing by zero\n","  return x_normed\n","\n","def standard(img, axes = [0, 1, 2]):\n","  # shape attribute returns a tuple (256, 256, 6)\n","  dims = tf.shape(img)\n","  H = dims[0]\n","  W = dims[1]\n","  C = dims[2]\n","  ninetyninth = tfp.stats.percentile(img, 99, axis = axes, interpolation = 'lower')\n","  # create a list of HxW tensors holding 99th percentile values per band\n","  maximum = tf.reshape(tf.repeat(ninetyninth, repeats = [H*W, H*W, H*W, H*W, H*W, H*W]), [H,W,C]) \n","  minimum = tf.reshape(tf.repeat([0.0], repeats = [H*W*C]), shape = (H, W, C))\n","  #maximum = tf.reshape(tf.repeat([100.0], repeats = [H*W*C]), shape = (H, W, C))\n","  clipped = tf.clip_by_value(img, clip_value_min = minimum, clip_value_max = maximum)\n","  scaled = tf.divide(tf.subtract(clipped, minimum), tf.subtract(maximum, minimum))\n","  return scaled\n","\n","def aug_img(img):\n","  \"\"\"\n","  Perform morphometric augmentation of input image\n","  Parameters:\n","    img (3D array):\n","  Returns:\n","    3D image array:\n","  \"\"\"\n","  outDims = tf.shape(img)[0:1]\n","  x = tf.image.random_flip_left_right(img)\n","  x = tf.image.random_flip_up_down(x)\n","  x = rotated = tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","  #since were gonna map_fn this on a 4d image, output must be 3d, so squeeze the artificial 'sample' dimension\n","  return tf.squeeze(x)\n","\n","def preprocess(img, labels):\n","  dims = tf.shape(img)\n","  #need to combine labels and bands for morphological transformations\n","  comb = tf.concat([img, tf.expand_dims(labels, axis = 2)], axis = 2)\n","  aug = aug_img(comb)\n","  #aug = tf.map_fn(fn = aug_img, elems = comb)\n","  labels = tf.squeeze(aug[:, :, -1])\n","  band_stack = color(aug[:, :, 0:dims[2]])\n","  return band_stack, labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rWXrvBE4607G"},"source":["## Funciones lectura de los datos"]},{"cell_type":"code","metadata":{"id":"WWZ0UXCVMyJP"},"source":["def parse_tfrecord(example_proto):\n","  \"\"\"The parsing function.\n","  Read a serialized example into the structure defined by FEATURES_DICT.\n","  Args:\n","    example_proto: a serialized Example.\n","  Returns: \n","    A dictionary of tensors, keyed by feature name.\n","  \"\"\"\n","  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n","\n","def to_tuple(inputs):\n","  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n","  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n","  Args:\n","    inputs: A dictionary of tensors, keyed by feature name.\n","  Returns: \n","    A dtuple of (inputs, outputs).\n","  \"\"\"\n","  inputsList = [inputs.get(key) for key in FEATURES]\n","  stacked = tf.stack(inputsList, axis=0)\n","  # Convert from CHW to HWC\n","  stacked = tf.transpose(stacked, [1, 2, 0])\n","  # Perform image augmentation\n","  stacked = aug_img(stacked)\n","  # split input bands and labels\n","  bands = stacked[:,:,:len(BANDS)]\n","  labels = stacked[:,:,len(BANDS):]\n","  # do color augmentation on input features\n","  bands = aug_color(bands)\n","  # standardize each patch of bands\n","  bands = normalize(bands, [0, 1])\n","  return bands, labels \n","\n","def get_dataset(pattern):\n","  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n","  Get all the files matching the pattern, parse and convert to tuple.\n","  Args:\n","    pattern: A file pattern to match in a Cloud Storage bucket.\n","  Returns: \n","    A tf.data.Dataset\n","  \"\"\"\n","  glob = tf.io.gfile.glob(pattern)\n","  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n","  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n","  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n","  return dataset\n","\n","def get_training_dataset(pattern):\n","\t\"\"\"Get the preprocessed training dataset\n","\tParameters:\n","\t\tpattern (str): directory path to training data\n","  Returns: \n","    A tf.data.Dataset of training data.\n","  \"\"\"\n","\tdataset = get_dataset(pattern)\n","\tdataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","\treturn dataset\n","\n","def get_val_eval_dataset(pattern):\n","\t\"\"\"\n","\tGet the preprocessed evaluation dataset\n","\tParameters:\n","\t\tpattern (str): directory path to training data\n","  Returns: \n","    A tf.data.Dataset of evaluation data.\n","  \"\"\"\n","\tdataset = get_dataset(pattern)\n","\tdataset = dataset.batch(1).repeat()\n","\treturn dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1D4O-qohbNn9"},"source":["## Otras funciones"]},{"cell_type":"code","metadata":{"id":"ZqBdM50IOWEp"},"source":["import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","\n","class PlotLearning(tf.keras.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.i = 0\n","        self.x = []\n","        self.losses = []\n","        self.val_losses = []\n","        self.iou = []\n","        self.val_iou = []\n","        self.f1score = []\n","        self.val_f1score = []\n","        self.fig = plt.figure()\n","        \n","        self.logs = []\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        \n","        self.logs.append(logs)\n","        self.x.append(self.i)\n","        self.losses.append(logs.get('loss'))\n","        self.val_losses.append(logs.get('val_loss'))\n","        self.iou.append(logs.get('iou_score'))\n","        self.val_iou.append(logs.get('val_iou_score'))\n","        self.f1score.append(logs.get('f1-score'))\n","        self.val_f1score.append(logs.get('val_f1-score'))\n","        self.i += 1\n","        f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, figsize=(15,5))\n","        \n","        clear_output(wait=True)\n","        \n","        ax1.set_yscale('log')\n","        ax1.plot(self.x, self.losses, label=\"loss\")\n","        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n","        ax1.legend()\n","        \n","        ax2.plot(self.x, self.iou, label=\"iou\")\n","        ax2.plot(self.x, self.val_iou, label=\"val_iou\")\n","        ax2.legend()\n","\n","        ax3.plot(self.x, self.f1score, label=\"f1score\")\n","        ax3.plot(self.x, self.val_f1score, label=\"val_f1score\")\n","        ax3.legend()\n","\n","        plt.show();\n","        \n","plot = PlotLearning()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xDbwRKfEPQJZ"},"source":["## Cargar los datos"]},{"cell_type":"code","metadata":{"id":"oL6KKglZPsHf"},"source":["def cargaDatos(indir, periodo, particion):\n","  if periodo == 'T1-T2':\n","    periodo = ''\n","  particionPattern = join(indir, f'{particion}_' + periodo + '*.tfrecord.gz')\n","  listParticion = tf.io.gfile.glob(particionPattern)\n","  print(f'La particion {particion} del periodo {periodo} tiene un total de {len(listParticion)} TFRecords')\n","  data = get_training_dataset(listParticion)\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bk9rFou0J_dZ"},"source":["periodo = 'T1-T2' #T1-T2 para ambos\n","n = 5\n","N = 50\n","\n","#indir = join('/content/gdrive/My Drive',PROYECTO,'datos',f'n{n}_N{N}')\n","indir = join('/content/gdrive/My Drive',PROYECTO)\n","\n","# entrenamiento\n","training = cargaDatos(indir,periodo,'training')\n","validation = cargaDatos(indir,periodo,'validation')\n","evaluation = cargaDatos(indir,periodo,'eval')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JufmJgYVowB"},"source":["indir = join('/content/gdrive/My Drive',PROYECTO)\n","particionPattern = join(indir, 'training_T' + '*.tfrecord.gz')\n","listParticion = tf.io.gfile.glob(particionPattern)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9JIE7Yl87lgU"},"source":["# Modelado"]},{"cell_type":"code","metadata":{"id":"wsnnnz56yS3l"},"source":["from tensorflow.python.keras import layers\n","from tensorflow.python.keras import losses\n","from tensorflow.python.keras import models\n","from tensorflow.python.keras import metrics\n","from tensorflow.python.keras import optimizers\n","from tensorflow.keras import backend as K\n","from segmentation_models.base import Loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qonMr0EwsbjC"},"source":["##función TverskyLoss\n","class TverskyLoss(Loss):\n","    def __init__(self, alpha=0.45, beta=0.55, class_weights=None):\n","        super().__init__(name='tversky_loss')\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.class_weights = class_weights if class_weights is not None else 1.\n","\n","    def __call__(self, gt, pr):\n","        return _tversky_loss(\n","            gt=gt, \n","            pr=pr, \n","            alpha=self.alpha, \n","            beta=self.beta, \n","            class_weights=self.class_weights\n","        )\n","\n","\n","class FocalTverskyLoss(Loss):\n","    def __init__(self, alpha=0.45, beta=0.55, gamma=2.5, class_weights=None):\n","        super().__init__(name='tversky_loss')\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.gamma = gamma\n","        self.class_weights = class_weights if class_weights is not None else 1.\n","\n","    def __call__(self, gt, pr):\n","        return _focal_tversky_loss(\n","            gt=gt, \n","            pr=pr, \n","            alpha=self.alpha, \n","            beta=self.beta, \n","            gamma=self.gamma, \n","            class_weights=self.class_weights\n","        )\n","\n","def _tversky_index(gt, pr, alpha, beta):\n","    eps = K.epsilon()\n","    pr = tf.clip_by_value(pr, eps, 1 - eps)\n","    reduce_axes = [0, 1, 2]\n","    tp = tf.reduce_sum(gt * pr, axis=reduce_axes)\n","    fp = tf.reduce_sum(pr, axis=reduce_axes) - tp\n","    fn = tf.reduce_sum(gt, axis=reduce_axes) - tp\n","    return (tp + eps) / (tp + alpha*fp + beta*fn + eps)\n","\n","\n","def _tversky_loss(gt, pr, alpha=0.45, beta=0.55, class_weights=1., **kwargs):\n","    index = _tversky_index(gt, pr, alpha, beta) * class_weights\n","    return 1.0 - tf.reduce_mean(index)\n","\n","def _focal_tversky_loss(gt, pr, alpha=0.45, beta=0.55, gamma=2.5, class_weights=1., **kwargs):\n","    gamma = tf.clip_by_value(gamma, 1.0, 3.0)\n","    index =_tversky_index(gt, pr, alpha, beta) * class_weights\n","    loss = K.pow((1.0 - index), (1.0 / gamma))\n","    return K.mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B468qQGsmOnP"},"source":["def conv_block(input_tensor, num_filters):\n","\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n","\tencoder = layers.BatchNormalization()(encoder)\n","\tencoder = layers.Activation('relu')(encoder)\n","\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n","\tencoder = layers.BatchNormalization()(encoder)\n","\tencoder = layers.Activation('relu')(encoder)\n","\treturn encoder\n","\n","def encoder_block(input_tensor, num_filters):\n","\tencoder = conv_block(input_tensor, num_filters)\n","\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n","\treturn encoder_pool, encoder\n","\n","def decoder_block(input_tensor, concat_tensor, num_filters):\n","\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n","\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n","\tdecoder = layers.BatchNormalization()(decoder)\n","\tdecoder = layers.Activation('relu')(decoder)\n","\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n","\tdecoder = layers.BatchNormalization()(decoder)\n","\tdecoder = layers.Activation('relu')(decoder)\n","\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n","\tdecoder = layers.BatchNormalization()(decoder)\n","\tdecoder = layers.Activation('relu')(decoder)\n","\treturn decoder\n","\n","def unet_model():\n","  inputs = layers.Input(shape=[None, None, len(BANDS)])\n","  encoder0_pool, encoder0 = encoder_block(inputs, 32)\n","  encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n","  encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n","  encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n","  encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n","  center = conv_block(encoder4_pool, 1024)# center\n","  decoder4 = decoder_block(center, encoder4, 512)\n","  decoder3 = decoder_block(decoder4, encoder3, 256)\n","  decoder2 = decoder_block(decoder3, encoder2, 128)\n","  decoder1 = decoder_block(decoder2, encoder1, 64)\n","  decoder0 = decoder_block(decoder1, encoder0, 32)\n","  segmentation = layers.Conv2D(1, (1, 1), activation='sigmoid', name='seg')(decoder0)\n","\n","  return \tmodels.Model(inputs=[inputs], outputs=[segmentation])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"avJOvoYwl4YY"},"source":["def _get_model(periodo, modelname, modeltype, costloss, pretrained=True, rgb=True):\n","  \n","  if costloss == 'diceloss':\n","    target_loss = sm.losses.DiceLoss()\n","  elif costloss == 'focalloss':\n","    target_loss = sm.losses.BinaryFocalLoss()\n","  elif costloss == 'dicefocalloss':\n","    loss1 = sm.losses.DiceLoss()\n","    loss2 = sm.losses.BinaryFocalLoss()\n","    target_loss = loss1 + (1 * loss2)\n","  elif costloss == 'focaltverskyloss':\n","    target_loss = FocalTverskyLoss()\n","  elif costloss == 'BCEloss':\n","    target_loss = sm.losses.BinaryCELoss()\n","  elif costloss == 'jaccardloss':\n","    target_loss = sm.losses.JaccardLoss()\n","\n","  if modelname == 'unet-sm':\n","    if pretrained and not rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} usando bandas RGB-NIR e iniciado con los pesos de imagenet y función de perdida {costloss}')\n","      base_model = sm.Unet(backbone_name=modeltype, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","      inp = layers.Input(shape=(None, None, 10))\n","      l1 = layers.Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n","      out = base_model(l1)\n","      model = models.Model(inp, out, name=base_model.name)\n","    elif pretrained and rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} usando bandas RGB e iniciado con los pesos de imagenet y función de perdida {costloss}')\n","      model = sm.Unet(backbone_name=modeltype, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","    elif rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB y función de perdida {costloss}')\n","      model = sm.Unet(modeltype, classes=1, activation='sigmoid', encoder_weights=None)\n","    else:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB-NIR y función de perdida {costloss}')\n","      model = sm.Unet(modeltype, input_shape=(None, None, 10), classes=1, activation='sigmoid', encoder_weights=None)\n","  elif modelname == 'fpn-sm':\n","    if pretrained and not rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} usando bandas RGB-NIR e iniciado con los pesos de imagenet y función de perdida {costloss}')\n","      base_model = sm.FPN(backbone_name=modeltype, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","      inp = layers.Input(shape=(None, None, 10))\n","      l1 = layers.Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n","      out = base_model(l1)\n","      model = models.Model(inp, out, name=base_model.name)\n","    elif pretrained and rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} usando bandas RGB e iniciado con los pesos de imagenet y función de perdida {costloss}')\n","      model = sm.FPN(backbone_name=modeltype, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","    elif rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB y función de perdida {costloss}')\n","      model = sm.FPN(modeltype, classes=1, activation='sigmoid', encoder_weights=None)\n","    else:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB-NIR y función de perdida {costloss}')\n","      model = sm.FPN(modeltype, input_shape=(None, None, 10), classes=1, activation='sigmoid', encoder_weights=None)\n","  elif modelname == 'unet-manual':\n","      model = unet_model()\n","      if rgb:\n","        print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB y función de perdida {costloss}')\n","      else:\n","        print(f'El modelo {modeltype} usando el metodo {modelname} va ser entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB-NIR y función de perdida {costloss}')\n","\n","  optim = tf.keras.optimizers.Adam(1e-4)\n","\n","  total_loss = target_loss\n","\n","  metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n","\n","  # compile keras model with defined optimozer, loss and metrics\n","  model.compile(optim, total_loss, metrics)\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PA2gJENE8-J1"},"source":["ruta_assets = 'users/mazarazaa'\n","\n","if periodo in ['T1','T2']:\n","  training_samples = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{periodo}_muestras_training-N{N}_n{n}'))\n","  validation_samples = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{periodo}_muestras_validation-N{N}_n{n}'))\n","  evaluation_samples = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{periodo}_muestras_evaluation-N{N}_n{n}'))\n","\n","elif periodo == 'T1-T2':\n","  t1 = str.split(periodo, '-')[0]\n","  t2 = str.split(periodo, '-')[1]\n","  #t3 = str.split(periodo, '-')[2]\n","  training_samples_T1 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t1}_muestras_training-N{N}_n{n}'))\n","  validation_samples_T1 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t1}_muestras_validation-N{N}_n{n}'))\n","  evaluation_samples_T1 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t1}_muestras_evaluation-N{N}_n{n}'))\n","  training_samples_T2 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t2}_muestras_training-N{N}_n{n}'))\n","  validation_samples_T2 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t2}_muestras_validation-N{N}_n{n}'))\n","  evaluation_samples_T2 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t2}_muestras_evaluation-N{N}_n{n}'))\n","  # training_samples_T3 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t3}_muestras_training-N{N}_n{n}'))\n","  # validation_samples_T3 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t3}_muestras_validation-N{N}_n{n}'))\n","  # evaluation_samples_T3 = ee.FeatureCollection(join(ruta_assets,f'{PROYECTO}_{t3}_muestras_evaluation-N{N}_n{n}'))\n","\n","  training_samples = training_samples_T1.merge(training_samples_T2)#.merge(training_samples_T3)\n","  validation_samples = validation_samples_T1.merge(validation_samples_T2)#.merge(validation_samples_T3)\n","  evaluation_samples = evaluation_samples_T1.merge(evaluation_samples_T2)#.merge(evaluation_samples_T3)\n","\n","TRAIN_SIZE = training_samples.size().getInfo()\n","VAL_SIZE = validation_samples.size().getInfo()\n","EVAL_SIZE = evaluation_samples.size().getInfo()\n","\n","print(f'TRAIN_SIZE: {TRAIN_SIZE}')\n","print(f'VAL_SIZE: {VAL_SIZE}')\n","print(f'EVAL_SIZE: {EVAL_SIZE}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXt0GVTn1BHo"},"source":["modelname = 'unet-sm'\n","backbone = 'efficientnetb3'\n","#backbone = 'resnet34' //backbone para modelo unet-sm\n","costfunction = 'dicefocalloss' #'focaltverskyloss'\n","pretrained = True\n","rgb = False\n","earlystop = False\n","\n","EPOCHS = 50\n","\n","if pretrained:\n","  weights = 'pretrained'\n","else:\n","  weights = 'scratch'\n","\n","if rgb:\n","  inputdata = 'RGB'\n","else:\n","  inputdata = '4RGBNIR'\n","\n","if earlystop:\n","  es = 'withES'\n","else:\n","  es = 'withoutES'\n","\n","model_dir = join('/content/gdrive/My Drive',PROYECTO,'modelos',f'{modelname}_{backbone}_{periodo}_epochs{EPOCHS}_{costfunction}_{weights}_{inputdata}_{es}')\n","\n","# set up tensorboard and checkpoint callbacks\n","log_dir = join(model_dir,'logs')\n","\n","os.makedirs(model_dir, exist_ok=True)\n","os.makedirs(log_dir, exist_ok=True)\n","\n","tensorboard = tf.keras.callbacks.TensorBoard(log_dir= log_dir)\n","\n","filename = 'model-ep{epoch:03d}.hdf5'\n","\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    os.path.join(model_dir, filename),\n","    monitor='val_iou_score',\n","    save_weights_only=True,\n","    verbose=1,\n","    save_best_only=True,\n","    mode='max'\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uu_E7OTDBCoS"},"source":["## Crear modelo"]},{"cell_type":"code","metadata":{"id":"5yQPxgtISibx"},"source":["m = _get_model(periodo, modelname, backbone, costfunction, pretrained, rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLS3qcJ4zu51"},"source":["!pip install --force-reinstall tensorflow==2.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kisPxRMzxNC"},"source":["!pip install --force-reinstall keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uqcEjCJsMQXW"},"source":["Configuraciones del callback"]},{"cell_type":"code","metadata":{"id":"MOx_UGVR6ZYh"},"source":["from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n","\n","# Learning rate dinamica (sin mucha influencia)\n","# reduce_lr = ReduceLROnPlateau(\n","#     monitor='loss',\n","#     factor=0.5,min_lr=1e-7,\n","#     patience=10,\n","#     verbose=1,\n","#     mode='auto')\n","\n","early_stopping = EarlyStopping(patience=15, verbose=1,monitor=\"val_iou_score\", mode='max')\n","\n","if earlystop:\n","  callbacks = [checkpoint, early_stopping, tensorboard, plot]\n","else:\n","  callbacks = [checkpoint, tensorboard, plot]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3KoqoYVabrTy"},"source":["##Iniciar entrenamiento"]},{"cell_type":"code","metadata":{"id":"vr2iVQxsoWnX"},"source":["history = m.fit(\n","            x = training, \n","            steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE), \n","            epochs=EPOCHS, \n","            callbacks=callbacks, \n","            validation_data=validation, \n","            validation_steps=int(VAL_SIZE/BATCH_SIZE))\n","\n","np.save(join(model_dir,'historia_modelo.npy'),history.history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6tTXDDXgcTZ3"},"source":["##Verificar entrenamiento y determinar exactitud en los datos de evaluación"]},{"cell_type":"code","metadata":{"id":"XWDMWMD_Us0R"},"source":["hist_data = np.load(join(model_dir,'historia_modelo.npy'), allow_pickle=True).item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGeT89kbWxQv"},"source":["# Plot training & validation iou_score values\n","plt.figure(figsize=(30, 5))\n","plt.subplot(121)\n","plt.plot(hist_data['iou_score'])\n","plt.plot(hist_data['val_iou_score'])\n","plt.title('Model iou_score')\n","plt.ylabel('iou_score')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","\n","# Plot training & validation loss values\n","plt.subplot(122)\n","plt.plot(np.log(hist_data['loss']))\n","plt.plot(np.log(hist_data['val_loss']))\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iz0pPVjcco-2"},"source":["#Evaluar resultados en la partición de evaluación\n","evalMetrics = m.evaluate(x=evaluation, steps = EVAL_SIZE, verbose = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zvIqqpNXqJSE"},"source":["##Continuar entrenamiento en modelo salvado\n","Esto se recomienda en caso de que se necesita entrenar por más epocas el modelo. Se debe cargar los componentes de funciones delo modelo"]},{"cell_type":"code","metadata":{"id":"IT_b74TqCGdb"},"source":["def load_model_weights(periodo, model_dir, modelname, modeltype, costloss, pretrained=True, rgb=True):\n","  \n","  if costloss == 'diceloss':\n","    target_loss = sm.losses.DiceLoss()\n","  elif costloss == 'focalloss':\n","    target_loss = sm.losses.BinaryFocalLoss()\n","  elif costloss == 'dicefocalloss':\n","    loss1 = sm.losses.DiceLoss()\n","    loss2 = sm.losses.BinaryFocalLoss()\n","    target_loss = loss1 + (1 * loss2)\n","  elif costloss == 'focaltverskyloss':\n","    target_loss = FocalTverskyLoss()\n","  elif costloss == 'BCEloss':\n","    target_loss = sm.losses.BinaryCELoss()\n","  elif costloss == 'jaccardloss':\n","    target_loss = sm.losses.JaccardLoss()\n","\n","  if modelname == 'unet-sm':\n","    if pretrained and not rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} usando bandas RGB-NIR e iniciado con los pesos de imagenet y función de perdida {costloss}')\n","      base_model = sm.Unet(backbone_name=modeltype, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","      inp = layers.Input(shape=(None, None, 10))\n","      l1 = layers.Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n","      out = base_model(l1)\n","      model = models.Model(inp, out, name=base_model.name)\n","    elif pretrained and rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} usando bandas RGB e iniciado con los pesos de imagenet y función de perdida {costloss}')\n","      model = sm.Unet(backbone_name=modeltype, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","    elif rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB y función de perdida {costloss}')\n","      model = sm.Unet(modeltype, classes=1, activation='sigmoid', encoder_weights=None)\n","    else:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB-NIR y función de perdida {costloss}')\n","      model = sm.Unet(modeltype, input_shape=(None, None, 8), classes=1, activation='sigmoid', encoder_weights=None)\n","  elif modelname == 'fpn-sm':\n","    if pretrained and not rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue para el periodo {periodo} entrenado usando bandas RGB-NIR e iniciado con los pesos de imagenet y función de perdida {costloss}')\n","      base_model = sm.FPN(backbone_name=modeltype, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","      inp = layers.Input(shape=(None, None, 10))\n","      l1 = layers.Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n","      out = base_model(l1)\n","      model = models.Model(inp, out, name=base_model.name)\n","    elif pretrained and rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} usando bandas RGB e iniciado con los pesos de imagenet y función de perdida {costloss}')\n","      model = sm.FPN(backbone_name=modeltype, encoder_weights='imagenet', classes=1, activation='sigmoid')\n","    elif rgb:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB y función de perdida {costloss}')\n","      model = sm.FPN(modeltype, classes=1, activation='sigmoid', encoder_weights=None)\n","    else:\n","      print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB-NIR y función de perdida {costloss}')\n","      model = sm.FPN(modeltype, input_shape=(None, None, 10), classes=1, activation='sigmoid', encoder_weights=None)\n","  elif modelname == 'unet-manual':\n","      model = unet_model()\n","      if rgb:\n","        print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB y función de perdida {costloss}')\n","      else:\n","        print(f'El modelo {modeltype} usando el metodo {modelname} va ser cargado y fue entrenado para el periodo {periodo} desde su inicio (scratch) usando bandas RGB-NIR y función de perdida {costloss}')\n","\n","  optim = tf.keras.optimizers.Adam(1e-4)\n","  \n","  total_loss = target_loss\n","\n","  metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n","\n","  model.load_weights(model_dir + '/model-ep027.hdf5')\n","\n","  # compile keras model with defined optimozer, loss and metrics\n","  model.compile(optim, total_loss, metrics)\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0xgBhsaqInV"},"source":["modelname = 'unet-sm'\n","backbone = 'efficientnetb3'\n","#backbone = 'resnet34' //backbone para modelo unet-sm\n","costfunction = 'dicefocalloss' #'focaltverskyloss'\n","pretrained = True\n","rgb = False\n","earlystop = False\n","\n","periodo = 'T1-T2'\n","EPOCHS = 35\n","\n","if pretrained:\n","  weights = 'pretrained'\n","else:\n","  weights = 'scratch'\n","\n","if rgb:\n","  inputdata = 'RGB'\n","else:\n","  inputdata = '4RGBNIR'\n","\n","if earlystop:\n","  es = 'withES'\n","else:\n","  es = 'withoutES'\n","\n","model_dir = join('/content/gdrive/My Drive',PROYECTO,'modelos',f'{modelname}_{backbone}_{periodo}_epochs{EPOCHS}_{costfunction}_{weights}_{inputdata}_{es}')\n","\n","#bring in the architecture and best weights from Drive\n","m = load_model_weights(periodo, model_dir, modelname, backbone, costfunction, pretrained, rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"249RZynIQOA2"},"source":["hist_data = np.load(join(model_dir,'historia_modelo.npy'), allow_pickle=True).item()\n","# Plot training & validation iou_score values\n","plt.figure(figsize=(30, 5))\n","plt.subplot(121)\n","plt.plot(hist_data['iou_score'])\n","plt.plot(hist_data['val_iou_score'])\n","plt.title('Model iou_score')\n","plt.ylabel('iou_score')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","\n","# Plot training & validation loss values\n","plt.subplot(122)\n","plt.plot(np.log(hist_data['loss']))\n","plt.plot(np.log(hist_data['val_loss']))\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"umZy0rBzs1Th"},"source":["#lets see where were at\n","evalMetrics = m.evaluate(x=evaluation, steps = EVAL_SIZE, verbose = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X70_M1NMZ1bp"},"source":["Evaluar Prediccion"]},{"cell_type":"code","metadata":{"id":"ARhepJmfZhdE"},"source":["#Inspect the prediction outputs\n","predictions = m.predict(evaluation, steps=50, verbose=1)\n","# for prediction in predictions:\n","#   print(predictions.shape)\n","fig, axs = plt.subplots(10,5, figsize=(15, 15), facecolor='w', edgecolor='k')\n","fig.subplots_adjust(hspace = .5, wspace=.001)\n","\n","axs = axs.ravel()\n","\n","for i in range(50):\n","    axs[i].imshow(predictions[i,:,:,0],cmap='RdYlGn')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2pQ_SJta_TJ"},"source":["def doExport(image, out_image_base, kernel_buffer, region, resolucion):\n","  \"\"\"\n","  Run an image export task on which to run predictions.  Block until complete.\n","  Parameters:\n","    image (ee.Image): image to be exported for prediction\n","    path (str): google cloud directory path for export\n","    out_image_base (str): base filename of exported image\n","    kernel_buffer (array<int>): pixels to buffer the prediction patch. half added to each side\n","    region (ee.Geometry):\n","  \"\"\"\n","  image_export_options = {\n","      'patchDimensions': KERNEL_SHAPE,\n","      'kernelSize': kernel_buffer,\n","      'compressed': True,\n","      'maxFileSize': 104857600\n","  }\n","\n","  # Setup the task.\n","  task = ee.batch.Export.image.toDrive(\n","    image=image.select(BANDS),\n","    description=out_image_base,\n","    fileNamePrefix=out_image_base,\n","    folder=PROYECTO,\n","    scale=resolucion,\n","    fileFormat='TFRecord',\n","    maxPixels = 1e13,\n","    region=region.getInfo()['coordinates'],\n","    formatOptions=image_export_options,\n","  )\n","\n","  task.start()\n","\n","  # Block until the task completes.\n","  print('Running image export to Google Drive...')\n","  import time\n","  while task.active():\n","    time.sleep(30)\n","\n","  # Error condition\n","  if task.status()['state'] != 'COMPLETED':\n","    print('Error with image export.')\n","  else:\n","    print('Image export completed.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzMUOWyAQZat"},"source":["def doExportg(image, out_image_base, kernel_buffer, region, resolucion):\n","  \"\"\"\n","  Run an image export task on which to run predictions.  Block until complete.\n","  Parameters:\n","    image (ee.Image): image to be exported for prediction\n","    path (str): google cloud directory path for export\n","    out_image_base (str): base filename of exported image\n","    kernel_buffer (array<int>): pixels to buffer the prediction patch. half added to each side\n","    region (ee.Geometry):\n","  \"\"\"\n","  image_export_options = {\n","      'patchDimensions': KERNEL_SHAPE,\n","      'kernelSize': kernel_buffer,\n","      'compressed': True,\n","      'maxFileSize': 104857600\n","  }\n","\n","  # Setup the task.\n","  task = ee.batch.Export.image.toCloudStorage(\n","    image=image.select(BANDS),\n","    description=out_image_base,\n","    fileNamePrefix=out_image_base,\n","    bucket=BUCKET,\n","    scale=resolucion,\n","    fileFormat='TFRecord',\n","    maxPixels = 1e13,\n","    region=region.getInfo()['coordinates'],\n","    formatOptions=image_export_options,\n","  )\n","\n","  task.start()\n","\n","  # Block until the task completes.\n","  print('Running image export to Google Drive...')\n","  import time\n","  while task.active():\n","    time.sleep(30)\n","\n","  # Error condition\n","  if task.status()['state'] != 'COMPLETED':\n","    print('Error with image export.')\n","  else:\n","    print('Image export completed.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HwHunj47bANv"},"source":["def doPrediction(OUTPUT_FOLDER, out_image_base, kernel_buffer, region):\n","  \"\"\"\n","  Perform inference on exported imagery, upload to Earth Engine.\n","  Parameters:\n","    pred_path (str): Google cloud (or Drive) path storing prediction image files\n","    out_image_base (str): base filename for GEE asset\n","    kernel_buffer (Array<int>): length 2 array \n","    region (ee.Geometry)):\n","  \"\"\"\n","\n","  print('Looking for TFRecord files...')\n","  \n","  # Get a list of all the files in the output bucket.\n","  files_list  = glob.glob('/content/gdrive/My Drive' + '/' + OUTPUT_FOLDER + '/*')\n","  # Get only the files generated by the image export.\n","  exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]\n","  print(exported_files_list)\n","\n","  # Get the list of image files and the JSON mixer file.\n","  imageFilesList = []\n","  json_file = None\n","  for f in exported_files_list:\n","    if f.endswith('.tfrecord.gz'):\n","      imageFilesList.append(f)\n","    elif f.endswith('.json'):\n","      json_file = f\n","\n","  import json\n","  with open(json_file) as file:\n","    mixer = json.load(file)\n","  print(mixer)\n","  patches = mixer['totalPatches']\n","  print(patches)\n","  # Get set up for prediction.\n","  x_buffer = int(kernel_buffer[0] / 2)\n","  y_buffer = int(kernel_buffer[1] / 2)\n","\n","  buffered_shape = [\n","      KERNEL_SHAPE[0] + kernel_buffer[0],\n","      KERNEL_SHAPE[1] + kernel_buffer[1]]\n","\n","  imageColumns = [\n","    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32) \n","      for k in BANDS\n","  ]\n","\n","  imageFeaturesDict = dict(zip(BANDS, imageColumns))\n","\n","  def parse_image(example_proto):\n","    return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n","\n","  def toTupleImage(dic):\n","    inputsList = [dic.get(key) for key in BANDS]\n","    stacked = tf.stack(inputsList, axis=0)\n","    stacked = tf.transpose(stacked, [1, 2, 0])\n","    stacked = normalize(stacked, [0, 1])\n","    return stacked\n","  \n","  #Create dir prediction\n","  import os\n","  os.chdir('/content/gdrive/My Drive/'+OUTPUT_FOLDER)\n","  os.getcwd()\n","  if os.path.isdir('prediction'):\n","    print('existe directorio prediction')\n","  else:\n","    os.mkdir('prediction')\n","\n","  # Create a dataset(s) from the TFRecord file(s) in Cloud Storage.\n","  i = 0\n","  patches = 0\n","  written_files = []\n","  while i < len(imageFilesList):\n","    imageDataset = tf.data.TFRecordDataset(imageFilesList[i:i+100], compression_type='GZIP')\n","    imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n","    imageDataset = imageDataset.map(toTupleImage).batch(1)\n","    \n","    # Perform inference.\n","    print('Running predictions...')\n","    predictions = m.predict(imageDataset, steps=None, verbose=1)\n","    # print(predictions[0])\n","\n","    out_image_file = join('/content/gdrive/My Drive', OUTPUT_FOLDER,\n","                          'prediction',\n","                          '{}{}.TFRecord'.format(out_image_base, i))\n","    \n","    print('Writing predictions to ' + out_image_file + '...')\n","    writer = tf.io.TFRecordWriter(out_image_file)  \n","    for predictionPatch in predictions:\n","      print('Writing patch ' + str(patches) + '...')\n","      predictionPatch = predictionPatch[\n","          x_buffer:x_buffer+KERNEL_SIZE, y_buffer:y_buffer+KERNEL_SIZE]\n","\n","      # Create an example.\n","      example = tf.train.Example(\n","        features=tf.train.Features(\n","          feature={\n","            'probability': tf.train.Feature(\n","                float_list=tf.train.FloatList(\n","                    value=predictionPatch.flatten()))\n","          }\n","        )\n","      )\n","      # Write the example.\n","      writer.write(example.SerializeToString())\n","      patches += 1\n","\n","    writer.close()\n","    i += 100\n","    written_files.append(out_image_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_SMSpLuf0or"},"source":["def doPredictiong(OUTPUT_BUCKET, out_image_base, kernel_buffer, region):\n","  \"\"\"\n","  Perform inference on exported imagery, upload to Earth Engine.\n","  Parameters:\n","    pred_path (str): Google cloud (or Drive) path storing prediction image files\n","    out_image_base (str): base filename for GEE asset\n","    kernel_buffer (Array<int>): length 2 array \n","    region (ee.Geometry)):\n","  \"\"\"\n","\n","  print('Looking for TFRecord files...')\n","  \n","  # Get a list of all the files in the output bucket.\n","  files_list  = !gsutil ls 'gs://'{OUTPUT_BUCKET}\n","  # Get only the files generated by the image export.\n","  exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]\n","  print(exported_files_list)\n","\n","  # Get the list of image files and the JSON mixer file.\n","  imageFilesList = []\n","  json_file = None\n","  for f in exported_files_list:\n","    if f.endswith('.tfrecord.gz'):\n","      imageFilesList.append(f)\n","    elif f.endswith('.json'):\n","      json_file = f\n","\n","  imageFilesList.sort()\n","  print(imageFilesList)\n","  print(json_file)\n","  \n","  import json\n","  # with open(json_file) as file:\n","  #   mixer = json.load(file)\n","  # Load the contents of the mixer file to a JSON object.\n","  json_text = !gsutil cat {json_file}\n","  # Get a single string w/ newlines from the IPython.utils.text.SList\n","  mixer = json.loads(json_text.nlstr)\n","  print(mixer)\n","\n","  print(mixer)\n","  patches = mixer['totalPatches']\n","  print(patches)\n","  # Get set up for prediction.\n","  x_buffer = int(kernel_buffer[0] / 2)\n","  y_buffer = int(kernel_buffer[1] / 2)\n","\n","  buffered_shape = [\n","      KERNEL_SHAPE[0] + kernel_buffer[0],\n","      KERNEL_SHAPE[1] + kernel_buffer[1]]\n","\n","  imageColumns = [\n","    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32) \n","      for k in BANDS\n","  ]\n","\n","  imageFeaturesDict = dict(zip(BANDS, imageColumns))\n","\n","  def parse_image(example_proto):\n","    return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n","\n","  def toTupleImage(dic):\n","    inputsList = [dic.get(key) for key in BANDS]\n","    stacked = tf.stack(inputsList, axis=0)\n","    stacked = tf.transpose(stacked, [1, 2, 0])\n","    stacked = normalize(stacked, [0, 1])\n","    return stacked\n","  \n","  #Create dir prediction\n","  # import os\n","  # os.chdir('/content/gdrive/My Drive/'+OUTPUT_BUCKET)\n","  # os.getcwd()\n","  # if os.path.isdir('prediction'):\n","  #   print('existe directorio prediction')\n","  # else:\n","  #   os.mkdir('prediction')\n","\n","  # Create a dataset(s) from the TFRecord file(s) in Cloud Storage.\n","  i = 0\n","  patches = 0\n","  written_files = []\n","  while i < len(imageFilesList):\n","    imageDataset = tf.data.TFRecordDataset(imageFilesList[i:i+100], compression_type='GZIP')\n","    imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n","    imageDataset = imageDataset.map(toTupleImage).batch(1)\n","    \n","    # Perform inference.\n","    print('Running predictions...')\n","    predictions = m.predict(imageDataset, steps=None, verbose=1)\n","    # print(predictions[0])\n","\n","    # out_image_file = join('/content/gdrive/My Drive', OUTPUT_BUCKET,\n","    #                       'prediction',\n","    #                       '{}{}.TFRecord'.format(out_image_base, i))\n","    out_image_file = join('gs://', OUTPUT_BUCKET,\n","                          '{}{}.TFRecord'.format(out_image_base, i))\n","    \n","    print('Writing predictions to ' + out_image_file + '...')\n","    writer = tf.io.TFRecordWriter(out_image_file)  \n","    for predictionPatch in predictions:\n","      print('Writing patch ' + str(patches) + '...')\n","      predictionPatch = predictionPatch[\n","          x_buffer:x_buffer+KERNEL_SIZE, y_buffer:y_buffer+KERNEL_SIZE]\n","\n","      # Create an example.\n","      example = tf.train.Example(\n","        features=tf.train.Features(\n","          feature={\n","            'probability': tf.train.Feature(\n","                float_list=tf.train.FloatList(\n","                    value=predictionPatch.flatten()))\n","          }\n","        )\n","      )\n","      # Write the example.\n","      writer.write(example.SerializeToString())\n","      patches += 1\n","\n","    writer.close()\n","    i += 100\n","    written_files.append(out_image_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5WY8ilibOzn"},"source":["###subzonas###\n","aoi_eval = ee.FeatureCollection('users/mazarazaa/AreaInicialf_def')\n","#imagen = ee.Image('users/mazarazaa/2017_10_10_planet')\n","#imagen = ee.Image('users/mazarazaa/2017_12_14_planet') Generada\n","#imagen = ee.Image('users/mazarazaa/2018_03_10_planet')\n","#imagen = ee.Image('users/mazarazaa/2018_06_21_planet')\n","#imagen = ee.Image('users/mazarazaa/2018_12_10_planet') Generada\n","#imagen = ee.Image('users/mazarazaa/2019_02_16_planet')\n","#imagen = ee.Image('users/mazarazaa/2019_08_30_planet')\n","#imagen = ee.Image('users/mazarazaa/2019_11_18_planet') Generada\n","#imagen = ee.Image('users/mazarazaa/stacked_mosaic_2017_2019').select('b1', 'b2', 'b3', 'b4','b5', 'b6', 'b7', 'b8').rename('B', 'G', 'R', 'NIR','B2', 'G2', 'R2', 'NIR2').unmask(0) \n","fechai = [201512, 201606, 201612, 201706, 201712, 201806, 201812, 201906, 201912]\n","ruta = 'users/mazarazaa/'\n","for j in range(len(fechai)-1):\n","  rimagen1 = ruta + str(fechai[j]) + '_PLDef'\n","  rimagen2 = ruta + str(fechai[j+1]) + '_PLDef'\n","  imagen1 = ee.Image(rimagen1).select('b1', 'b2', 'b3', 'b4').rename('B', 'G', 'R', 'NIR').unmask(0)\n","  imagen2 = ee.Image(rimagen2).select('b1', 'b2', 'b3', 'b4').rename('B2', 'G2', 'R2', 'NIR2').unmask(0)\n","  ndvi1 = imagen1.normalizedDifference(['NIR', 'R']).rename('NDVI');\n","  ndvi2 = imagen2.normalizedDifference(['NIR2', 'R2']).rename('NDVI2');\n","  imagen = imagen1.addBands(ndvi1).addBands(imagen2).addBands(ndvi2)\n","  print(aoi_eval.getInfo())\n","  nc_kernel_buffer = [256, 256]\n","  aoi_fil = aoi_eval.filter(ee.Filter.eq('type','Feature'))\n","  resolucion = imagen.projection().nominalScale().getInfo()\n","  for i in range(aoi_eval.size().getInfo()):\n","    a = aoi_eval.filter(ee.Filter.eq('ID_new', i))\n","    img_eval = imagen.clip(a).float()\n","    imagen_name = 'eval_image_'+str(fechai[j])+'_'+str(fechai[j+1])+'5b'+str(i)\n","    print('Realizando imagen '+imagen_name)\n","    nc_region = a.geometry()\n","    print(img_eval.getInfo())\n","    doExportg(img_eval, imagen_name, nc_kernel_buffer, nc_region, resolucion)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zVRRWeRGzO5"},"source":["fechai = [201512, 201606, 201612, 201706, 201712, 201806, 201812, 201906, 201912]\n","ruta = 'users/mazarazaa/'\n","for i in range(len(fechai)-1):\n","  imagen1 = ruta + str(fechai[i]) + '_PLDef'\n","  imagen2 = ruta + str(fechai[i+1]) + '_PLDef'\n","  print(imagen1)\n","  print(imagen2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNBAgKZbceLo"},"source":["# ###subzonas###\n","# #aoi_eval = ee.FeatureCollection('users/mazarazaa/aoi2_eval_planet')\n","# aoi_eval = ee.FeatureCollection('users/mazarazaa/aois_imgplanet')\n","# imagen = ee.Image('users/mazarazaa/2018_03_10_planet').select('b1', 'b2', 'b3', 'b4').rename('B', 'G', 'R', 'NIR').unmask(0)\n","# print(aoi_eval.getInfo())\n","# nc_kernel_buffer = [64, 64]\n","# resolucion = imagen.projection().nominalScale().getInfo()\n","# for i in range(aoi_eval.size().getInfo()):\n","#   a = aoi_eval.filter(ee.Filter.eq('ID_new', i))\n","#   nc_region = a.geometry()\n","#   IMAGE_FILE_PREFIX = 'eval_image_Pl2017_64'+str(i)\n","#   doPrediction(OUTPUT_FOLDER = PROYECTO,\n","#              out_image_base = 'eval2_'+str(i),\n","#              kernel_buffer = nc_kernel_buffer,\n","#              region = nc_region)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KWvNrVtjbPb"},"source":["OUTPUT_BUCKET = 'mineriapr'\n","#aoi_eval = ee.FeatureCollection('users/mazarazaa/Area_eval_2017_2019')\n","aoi_eval = ee.FeatureCollection('users/mazarazaa/AreaInicialf_def')\n","#imagen = ee.Image('users/mazarazaa/stacked_mosaic_2017_2019').select('b1', 'b2', 'b3', 'b4','b5', 'b6', 'b7', 'b8').rename('B', 'G', 'R', 'NIR','B2', 'G2', 'R2', 'NIR2').unmask(0) \n","fechai = [201512, 201606, 201612, 201706, 201712, 201806, 201812, 201906, 201912]\n","ruta = 'users/mazarazaa/'\n","for j in range(len(fechai)-1):\n","  rimagen1 = ruta + str(fechai[j]) + '_PLDef'\n","  rimagen2 = ruta + str(fechai[j+1]) + '_PLDef'\n","  imagen1 = ee.Image(rimagen1).select('b1', 'b2', 'b3', 'b4').rename('B', 'G', 'R', 'NIR').unmask(0)\n","  imagen2 = ee.Image(rimagen2).select('b1', 'b2', 'b3', 'b4').rename('B2', 'G2', 'R2', 'NIR2').unmask(0)\n","  ndvi1 = imagen1.normalizedDifference(['NIR', 'R']).rename('NDVI');\n","  ndvi2 = imagen2.normalizedDifference(['NIR2', 'R2']).rename('NDVI2');\n","  imagen = imagen1.addBands(ndvi1).addBands(imagen2).addBands(ndvi2)\n","  print(aoi_eval.getInfo())\n","  nc_kernel_buffer = [256, 256]\n","  resolucion = imagen.projection().nominalScale().getInfo()\n","  for i in range(aoi_eval.size().getInfo()):\n","    a = aoi_eval.filter(ee.Filter.eq('ID_new', i))\n","    nc_region = a.geometry()\n","    IMAGE_FILE_PREFIX = 'eval_image_'+str(fechai[j])+'_'+str(fechai[j+1])+'5b'+str(i)\n","    doPredictiong(OUTPUT_BUCKET = 'mineriapr',\n","              out_image_base = str(fechai[j])+'_'+str(fechai[j+1])+'_5b35e'+str(i),\n","              kernel_buffer = nc_kernel_buffer,\n","              region = nc_region)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gz2eKxmmECF5"},"source":["aoi_eval = ee.FeatureCollection('users/mazarazaa/AreaInicialf_def')\n","#for i in range(aoi_eval.size().getInfo()):\n","fechai = [201512, 201606, 201612, 201706, 201712, 201806, 201812, 201906, 201912] #201512, 201606, 201612, 201706, 201712, 201806, 201812, 201906, 201912\n","ruta = 'users/mazarazaa/'\n","for j in range(len(fechai)-1):\n","  rimagen1 = ruta + str(fechai[j]) + '_PLDef'\n","  rimagen2 = ruta + str(fechai[j+1]) + '_PLDef'\n","  imagen1 = ee.Image(rimagen1).select('b1', 'b2', 'b3', 'b4').rename('B', 'G', 'R', 'NIR').unmask(0)\n","  imagen2 = ee.Image(rimagen2).select('b1', 'b2', 'b3', 'b4').rename('B2', 'G2', 'R2', 'NIR2').unmask(0)\n","  ndvi1 = imagen1.normalizedDifference(['NIR', 'R']).rename('NDVI');\n","  ndvi2 = imagen2.normalizedDifference(['NIR2', 'R2']).rename('NDVI2');\n","  imagen = imagen1.addBands(ndvi1).addBands(imagen2).addBands(ndvi2)\n","  for i in range(aoi_eval.size().getInfo()):\n","    out_image_base = str(fechai[j])+'_'+str(fechai[j+1])+'_5b35e'+str(i) +'0.TFRecord'\n","    OUTPUT_IMAGE_FILE = 'gs://mineriapr/' + out_image_base\n","    !gsutil ls -l {OUTPUT_IMAGE_FILE}\n","    name_img = 'pr_image_'+str(fechai[j])+'_'+str(fechai[j+1])+'_5b35e'+str(i)\n","\n","    OUTPUT_ASSET_ID = 'users/mazarazaa/' + name_img\n","    print('Uploading to ' + OUTPUT_ASSET_ID)\n","    print('Writing to file ' + OUTPUT_IMAGE_FILE)\n","    name_json = 'eval_image_'+str(fechai[j])+'_'+str(fechai[j+1])+'5b'+str(i)+'mixer.json'\n","    json_file = 'gs://mineriapr/'+name_json\n","    print(json_file)\n","\n","  !earthengine upload image --asset_id={OUTPUT_ASSET_ID} --pyramiding_policy=mode {OUTPUT_IMAGE_FILE} {json_file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXdXK_KrzUvF"},"source":["fechai = [201712, 201806]\n","ruta = 'users/mazarazaa/'\n","for j in range(len(fechai)-1):\n","  rimagen1 = ruta + str(fechai[j]) + '_PLDef'\n","  rimagen2 = ruta + str(fechai[j+1]) + '_PLDef'\n","  print(rimagen1)\n","  print(rimagen2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7WF04Jf40CT"},"source":["ee.batch.Task.list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTxAkyllxLr9"},"source":["predictions_image = ee.Image('users/mazarazaa/eval_pl_c3')\n","\n","prediction_vis = {\n","  'bands': 'probability',\n","  'min': 0,\n","  'max': 1,\n","}\n","#probability_vis = {'bands': ['Mineria', 'NoMineria'], 'max': 0.5}\n","\n","imagen_2017 = ee.Image('users/mazarazaa/2017_12_14_planet')\n","prediction_map_id = predictions_image.getMapId(prediction_vis)\n","#probability_map_id = predictions_image.getMapId(probability_vis)\n","mapid = imagen_2017.getMapId({'bands': ['b1', 'b2', 'b3'], 'min': 50, 'max': 1500})\n","\n","map = folium.Map(location=[6.32, -75.72], zoom_start=15)\n","folium.TileLayer(\n","  tiles=prediction_map_id['tile_fetcher'].url_format,\n","  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n","  overlay=True,\n","  name='prediction',\n",").add_to(map)\n","# folium.TileLayer(\n","#   tiles=probability_map_id['tile_fetcher'].url_format,\n","#   attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n","#   overlay=True,\n","#   name='probability',\n","# ).add_to(map)\n","folium.TileLayer(\n","  tiles=mapid['tile_fetcher'].url_format,\n","  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n","  overlay=True,\n","  name='image',\n",").add_to(map)\n","map.add_child(folium.LayerControl())\n","map"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1jzduPXDWNKt"},"source":["Nuevo Modelo"]},{"cell_type":"code","metadata":{"id":"z2h-g8kowwkw"},"source":["EPOCHS = 100\n","\n","model_dir = join('/content/gdrive/My Drive',PROYECTO,'modelos',f'{modelname}_{backbone}_{periodo}_epochs{EPOCHS}_{costfunction}_{weights}_{inputdata}_{es}')\n","\n","log_dir = model_dir + '/logs'\n","\n","os.makedirs(model_dir, exist_ok=True)\n","os.makedirs(log_dir, exist_ok=True)\n","\n","#set the monitored value (val_mean_io_u) to current evaluation output\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    join(model_dir, 'best_weights.hdf5'),\n","    monitor='val_iou_score',\n","    verbose=1,\n","    save_best_only=True,\n","    mode='max'\n","    )\n","\n","tensorboard = tf.keras.callbacks.TensorBoard(log_dir= log_dir)\n","\n","checkpoint.best = evalMetrics[1]\n","print(checkpoint.__dict__)\n","print(checkpoint.best)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOr6Gtf-w1Ck"},"source":["#Now keep training!\n","history = m.fit(\n","            x = training, \n","            steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE), \n","            epochs=EPOCHS, \n","            callbacks=callbacks, \n","            validation_data=validation, \n","            validation_steps=int(VAL_SIZE/BATCH_SIZE))\n","\n","np.save(join(model_dir,'historia_modelo.npy'),history.history)"],"execution_count":null,"outputs":[]}]}